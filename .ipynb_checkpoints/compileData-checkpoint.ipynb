{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "abrvKeys = {'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA', 'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA', 'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD', 'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS', 'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH', 'New Jersey': 'NJ', 'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullkeys = {'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas', 'CA': 'California', 'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland', 'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi', 'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada', 'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York', 'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina', 'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VT': 'Vermont', 'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia', 'WI': 'Wisconsin', 'WY': 'Wyoming'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key -> county, element -> list of: opioid deaths, FIPS code, unemployment, prescription per 100 people, education\n",
    "combinedDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first initialize the dictionary with every county and the list with opioid deaths using countyDeaths.csv\n",
    "with open(\"RF_datasets/countyDeaths.csv\") as countyFile:\n",
    "    countyData = csv.reader(countyFile, delimiter=\",\")\n",
    "    i = 0\n",
    "    for row in countyData:\n",
    "        if i > 0:\n",
    "            curIndex = row[0].index(\",\")\n",
    "            countyName = row[0][:curIndex]\n",
    "            countyState = row[0][curIndex + 2:]\n",
    "            abrvState =  abrvKeys[countyState]\n",
    "            curKey = countyName + \", \" + abrvState\n",
    "            combinedDict[curKey] = [float(row[1])]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary for files having different county names\n",
    "inconsistencies = {\n",
    "    \"Anchorage Borough/municipality, AK\": \"Anchorage Municipality, AK\",\n",
    "    \"Juneau Borough/city, AK\": \"Juneau City and Borough, AK\",\n",
    "    \"Sitka Borough/city, AK\": \"Sitka City and Borough, AK\",\n",
    "    \"Wrangell Borough/city, AK\": \"Wrangell City and Borough, AK\",\n",
    "    \"Yakutat Borough/city, AK\": \"Yakutat City and Borough, AK\",\n",
    "    \"San Francisco County/city, CA\": \"San Francisco County, CA\",\n",
    "    \"Broomfield County/city, CO\": \"Broomfield County, CO\",\n",
    "    \"Denver County/city, CO\": \"Denver County, CO\",\n",
    "    \"Honolulu County/city, HI\": \"Honolulu County, HI\",\n",
    "    \"Nantucket County/town, MA\": \"Nantucket County, MA\",\n",
    "    \"Dona Ana County, NM\": \"DoÃ±a Ana County, NM\",\n",
    "    \"Philadelphia County/city, PA\": \"Philadelphia County, PA\",\n",
    "    \"Petersburg Census Area, AK\": \"Petersburg Borough, AK\",\n",
    "    \"Bedford city, VA\": \"Bedford County, VA\"\n",
    "    \n",
    "}\n",
    "ignoreNames = [\"PR\",\n",
    "               \"US\",\n",
    "               \"Wrangell-Petersburg Census Area, AK\",\n",
    "               \"District of Columbia\",\n",
    "               \"Prince of Wales-Outer Ketchikan Census Area, AK\",\n",
    "               \"Skagway-Hoonah-Angoon Census Area, AK\",\n",
    "               \"Aleutian Islands, AK\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onto FIPS code and unemployment\n",
    "with open(\"RF_datasets/Unemployment.csv\") as employFile:\n",
    "    employData = csv.reader(employFile, delimiter=\",\")\n",
    "    i = 0\n",
    "    for row in employData:\n",
    "        if i > 7:\n",
    "            countyName = \"No_Data\"\n",
    "            if row[2] not in combinedDict:\n",
    "                if row[2] not in combinedDict and row[2] not in abrvKeys and not (row[1] in ignoreNames or row[2] in ignoreNames):\n",
    "                    countyName = inconsistencies[row[2]]\n",
    "            else:\n",
    "                countyName = row[2]\n",
    "            if countyName != \"No_Data\":\n",
    "                FIPS = int(row[0])\n",
    "                unemployRate = float(row[45])\n",
    "                combinedDict[countyName] = combinedDict[countyName] + [FIPS, unemployRate]\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findnth(string, substring, n):\n",
    "    parts = string.split(substring, n + 1)\n",
    "    if len(parts) <= n + 1:\n",
    "        return -1\n",
    "    return len(string) - len(parts[-1]) - len(substring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now the prescription per 100 people\n",
    "with open(\"RF_datasets/Prescription_Population_Combined.csv\") as presFile:\n",
    "    presData = csv.reader(presFile, delimiter=\" \")\n",
    "    i = 0\n",
    "    for row in presFile:\n",
    "        if i == 1:\n",
    "            #print(row)\n",
    "            pass\n",
    "        if i > 0:\n",
    "            #get county\n",
    "            curIndex1 = findnth(row, \",\", 0) + 2\n",
    "            curIndex2 = findnth(row, \",\", 2) - 1\n",
    "            tempName = row[curIndex1:curIndex2]\n",
    "            tempIndex = tempName.index(\",\")\n",
    "            countyName = tempName[:tempIndex]\n",
    "            countyState = tempName[tempIndex + 2:]\n",
    "            \n",
    "            #get prescription\n",
    "            curIndex3 = findnth(row, \",\", 14) + 1\n",
    "            curIndex4 = findnth(row, \",\", 15)\n",
    "            presNumb = row[curIndex3:curIndex4]\n",
    "            if presNumb != \"N/A\":\n",
    "                presNumb = float(presNumb)\n",
    "            \n",
    "            #add it to the dictionary\n",
    "            if countyState != \"District of Columbia\":\n",
    "                abrvState =  abrvKeys[countyState]\n",
    "                curKey = countyName + \", \" + abrvState\n",
    "                combinedDict[curKey] = combinedDict[curKey] + [presNumb]\n",
    "                \n",
    "            \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bd6a3d1c8870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mcountyName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempName\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcountyName\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"No_Data\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mcombinedDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcountyName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombinedDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcountyName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m46\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: "
     ]
    }
   ],
   "source": [
    "#lastly the education (percent of adults with a bachelor degree or higher)\n",
    "with open(\"RF_datasets/Education.csv\") as eduFile:\n",
    "    eduData = csv.reader(eduFile, delimiter=\",\")\n",
    "    i = 0\n",
    "    for row in eduData:\n",
    "        if i > 5:\n",
    "            countyName = \"No_Data\"\n",
    "            tempName = row[2] + \", \" + row[1]\n",
    "            \n",
    "            if tempName not in combinedDict:\n",
    "                if tempName not in combinedDict and tempName not in ignoreNames and tempName in inconsistencies:\n",
    "                    countyName = inconsistencies[tempName]\n",
    "            else:\n",
    "                countyName = tempName\n",
    "            if countyName != \"No_Data\":\n",
    "                combinedDict[countyName] = combinedDict[countyName] + [float(row[46])]  \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in combinedDict:\n",
    "    print(x, combinedDict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
