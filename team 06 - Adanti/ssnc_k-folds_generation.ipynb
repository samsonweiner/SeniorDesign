{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-Fold CV Splits Generation\n",
    "This file creates splits the data set into 5 folds for a 5-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "os.chdir(\"/Users/joejohnson/Documents/Research/Unilever/ssnc_absorb_model/splits_stratified_k_fold\")\n",
    "\n",
    "unilever_1_df = pd.read_csv(\"ingred_all_fields.csv\")\n",
    "print(len(unilever_1_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0    35\n",
      " 1.0     8\n",
      " 3.0    26\n",
      " 4.0    40\n",
      " 2.0    15\n",
      "Name: occlus_elast_cat, dtype: int64\n",
      "124\n"
     ]
    }
   ],
   "source": [
    "## augment data set with new feature - occlusive + elastomer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "unilever_1_df[\"occlus_elast_sum\"] = unilever_1_df[\"occlusive\"] + unilever_1_df[\"elastomer\"]\n",
    "unilever_1_df[\"occlus_elast_cat\"] = np.ceil((np.log(unilever_1_df[\"occlus_elast_sum\"] + 1)) - 0.45)\n",
    "unilever_1_df[\"occlus_elast_cat\"].where(unilever_1_df[\"occlus_elast_cat\"] < 4, 4, inplace=True)\n",
    "\n",
    "print(unilever_1_df[\"occlus_elast_cat\"].value_counts(sort = False))\n",
    "print(len(unilever_1_df))\n",
    "\n",
    "# create dataframe with only those records for which occlusive_cat < 4 (filters out the records with\n",
    "# high occlusive value)\n",
    "# unilever_2_df = unilever_1_df.loc[unilever_1_df[\"occlusive_cat\"] < 4]\n",
    "\n",
    "# print(unilever_2_df[\"occlusive_cat\"].value_counts(sort = False))\n",
    "# print(len(unilever_2_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0    69\n",
      " 1.0    35\n",
      " 3.0    10\n",
      " 4.0     5\n",
      " 2.0     5\n",
      "Name: occlusive_cat, dtype: int64\n",
      "124\n",
      "-0.0    69\n",
      " 1.0    35\n",
      " 3.0    10\n",
      " 2.0     5\n",
      "Name: occlusive_cat, dtype: int64\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "## augment data set with transformation on occlusive feature.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "unilever_1_df[\"occlusive_cat\"] = np.ceil((np.log(unilever_1_df[\"occlusive\"] + 1)) - 0.5)\n",
    "unilever_1_df[\"occlusive_cat\"].where(unilever_1_df[\"occlusive_cat\"] < 4, 4, inplace=True)\n",
    "\n",
    "# create dataframe with only those records for which occlusive_cat < 4 (filters out the records with\n",
    "# high occlusive value)\n",
    "unilever_2_df = unilever_1_df.loc[unilever_1_df[\"occlusive_cat\"] < 4]\n",
    "\n",
    "print(unilever_1_df[\"occlusive_cat\"].value_counts(sort = False))\n",
    "print(len(unilever_1_df))\n",
    "print(unilever_2_df[\"occlusive_cat\"].value_counts(sort = False))\n",
    "print(len(unilever_2_df))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_value_counts(df, df_name, fieldName):\n",
    "    print(fieldName + ' Distribution: ' + df_name)\n",
    "    print('Value \\t Percentage')\n",
    "    print(df[fieldName].value_counts() / len(df))\n",
    "    print('Total count: ' + str(len(df)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createStratifiedShuffleSplits(df, extreme_data, strat_feature, dest_directory) :\n",
    "    # creates 5-fold CV train/test 80/20 splits with stratified sampling, using a strat field supplied as an\n",
    "    # input parameter.\n",
    "    # \n",
    "    # Parameters:\n",
    "    #\n",
    "    # df -- the pandas dataframe to split into 5 folds\n",
    "    # extreme_data -- boolean value - True for creating splits for the data having extreme values of \n",
    "    #                                        strat field\n",
    "    #                                        False for creating splits for the data with non-extreme values\n",
    "    # strat_feature - name of the field to do stratified sampling on. occlus_elast_cat, or occlusive_cat\n",
    "    # dest_directory - destination directory for the splits files.\n",
    "    \n",
    "    print_value_counts(df, \"Complete Data Set\", strat_feature)\n",
    "    split = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "    i = 1\n",
    "    for train_index, test_index in split.split(df, df[strat_feature]):\n",
    "        # create train/test split from the indexes produced by the \n",
    "        # call on the StratShuffleSplit.split() method.\n",
    "        strat_train_set = df.loc[train_index]\n",
    "        strat_test_set = df.loc[test_index]\n",
    "\n",
    "        # report the distribution of records across occlusive categories.\n",
    "        # should be very similar to distribution for entire dataset.\n",
    "        print_value_counts(strat_train_set, 'training set ' + str(i), strat_feature)\n",
    "        print_value_counts(strat_test_set, 'test set ' + str(i), strat_feature)\n",
    "        \n",
    "        # filter in/out extreme occlus_elast_cat value data points from training set, test set\n",
    "        if not extreme_data:\n",
    "            non_extreme_occlus_elast_value = strat_train_set['occlus_elast_cat'] < 4\n",
    "            strat_train_set = strat_train_set[non_extreme_occlus_elast_value]\n",
    "            non_extreme_occlus_elast_value = strat_test_set['occlus_elast_cat'] < 4\n",
    "            strat_test_set = strat_test_set[non_extreme_occlus_elast_value]\n",
    "        else:\n",
    "            extreme_occlus_elast_value = strat_train_set['occlus_elast_cat'] >= 4\n",
    "            strat_train_set = strat_train_set[extreme_occlus_elast_value]\n",
    "            extreme_occlus_elast_value = strat_test_set['occlus_elast_cat'] >= 4\n",
    "            strat_test_set = strat_test_set[extreme_occlus_elast_value]\n",
    "            \n",
    "        # report the distribution of records across occlusive categories after removal\n",
    "        # of extreme value data points.\n",
    "        # should be very similar to distribution for entire dataset.\n",
    "        print_value_counts(strat_train_set, 'training set ' + str(i) + ' after high occlus/elast data points removed', strat_feature)\n",
    "        print_value_counts(strat_test_set, 'test set ' + str(i) + ' after high occlus/elast data points removed', strat_feature)\n",
    "\n",
    "        # save each train/test set split to a .csv file.\n",
    "        strat_train_set.to_csv(dest_directory + '/strat_fold_' + str(i) + '_train.csv')\n",
    "        strat_test_set.to_csv(dest_directory + '/strat_fold_' + str(i) + '_test.csv')\n",
    "\n",
    "        #increment index for next train/test split\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occlus_elast_cat Distribution: Complete Data Set\n",
      "Value \t Percentage\n",
      " 4.0    0.322581\n",
      "-0.0    0.282258\n",
      " 3.0    0.209677\n",
      " 2.0    0.120968\n",
      " 1.0    0.064516\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 124\n",
      "\n",
      "occlus_elast_cat Distribution: training set 1\n",
      "Value \t Percentage\n",
      " 4.0    0.323232\n",
      "-0.0    0.282828\n",
      " 3.0    0.212121\n",
      " 2.0    0.121212\n",
      " 1.0    0.060606\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 99\n",
      "\n",
      "occlus_elast_cat Distribution: test set 1\n",
      "Value \t Percentage\n",
      " 4.0    0.32\n",
      "-0.0    0.28\n",
      " 3.0    0.20\n",
      " 2.0    0.12\n",
      " 1.0    0.08\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 25\n",
      "\n",
      "occlus_elast_cat Distribution: training set 1 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "-0.0    0.417910\n",
      " 3.0    0.313433\n",
      " 2.0    0.179104\n",
      " 1.0    0.089552\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 67\n",
      "\n",
      "occlus_elast_cat Distribution: test set 1 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "-0.0    0.411765\n",
      " 3.0    0.294118\n",
      " 2.0    0.176471\n",
      " 1.0    0.117647\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 17\n",
      "\n",
      "occlus_elast_cat Distribution: training set 2\n",
      "Value \t Percentage\n",
      " 4.0    0.323232\n",
      "-0.0    0.282828\n",
      " 3.0    0.212121\n",
      " 2.0    0.121212\n",
      " 1.0    0.060606\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 99\n",
      "\n",
      "occlus_elast_cat Distribution: test set 2\n",
      "Value \t Percentage\n",
      " 4.0    0.32\n",
      "-0.0    0.28\n",
      " 3.0    0.20\n",
      " 2.0    0.12\n",
      " 1.0    0.08\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 25\n",
      "\n",
      "occlus_elast_cat Distribution: training set 2 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "-0.0    0.417910\n",
      " 3.0    0.313433\n",
      " 2.0    0.179104\n",
      " 1.0    0.089552\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 67\n",
      "\n",
      "occlus_elast_cat Distribution: test set 2 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "-0.0    0.411765\n",
      " 3.0    0.294118\n",
      " 2.0    0.176471\n",
      " 1.0    0.117647\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 17\n",
      "\n",
      "occlus_elast_cat Distribution: training set 3\n",
      "Value \t Percentage\n",
      " 4.0    0.323232\n",
      "-0.0    0.282828\n",
      " 3.0    0.212121\n",
      " 2.0    0.121212\n",
      " 1.0    0.060606\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 99\n",
      "\n",
      "occlus_elast_cat Distribution: test set 3\n",
      "Value \t Percentage\n",
      " 4.0    0.32\n",
      "-0.0    0.28\n",
      " 3.0    0.20\n",
      " 2.0    0.12\n",
      " 1.0    0.08\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 25\n",
      "\n",
      "occlus_elast_cat Distribution: training set 3 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "-0.0    0.417910\n",
      " 3.0    0.313433\n",
      " 2.0    0.179104\n",
      " 1.0    0.089552\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 67\n",
      "\n",
      "occlus_elast_cat Distribution: test set 3 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "-0.0    0.411765\n",
      " 3.0    0.294118\n",
      " 2.0    0.176471\n",
      " 1.0    0.117647\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 17\n",
      "\n",
      "occlus_elast_cat Distribution: training set 4\n",
      "Value \t Percentage\n",
      " 4.0    0.323232\n",
      "-0.0    0.282828\n",
      " 3.0    0.212121\n",
      " 2.0    0.121212\n",
      " 1.0    0.060606\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 99\n",
      "\n",
      "occlus_elast_cat Distribution: test set 4\n",
      "Value \t Percentage\n",
      " 4.0    0.32\n",
      "-0.0    0.28\n",
      " 3.0    0.20\n",
      " 2.0    0.12\n",
      " 1.0    0.08\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 25\n",
      "\n",
      "occlus_elast_cat Distribution: training set 4 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "-0.0    0.417910\n",
      " 3.0    0.313433\n",
      " 2.0    0.179104\n",
      " 1.0    0.089552\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 67\n",
      "\n",
      "occlus_elast_cat Distribution: test set 4 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "-0.0    0.411765\n",
      " 3.0    0.294118\n",
      " 2.0    0.176471\n",
      " 1.0    0.117647\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 17\n",
      "\n",
      "occlus_elast_cat Distribution: training set 5\n",
      "Value \t Percentage\n",
      " 4.0    0.323232\n",
      "-0.0    0.282828\n",
      " 3.0    0.212121\n",
      " 2.0    0.121212\n",
      " 1.0    0.060606\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 99\n",
      "\n",
      "occlus_elast_cat Distribution: test set 5\n",
      "Value \t Percentage\n",
      " 4.0    0.32\n",
      "-0.0    0.28\n",
      " 3.0    0.20\n",
      " 2.0    0.12\n",
      " 1.0    0.08\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 25\n",
      "\n",
      "occlus_elast_cat Distribution: training set 5 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "-0.0    0.417910\n",
      " 3.0    0.313433\n",
      " 2.0    0.179104\n",
      " 1.0    0.089552\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 67\n",
      "\n",
      "occlus_elast_cat Distribution: test set 5 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "-0.0    0.411765\n",
      " 3.0    0.294118\n",
      " 2.0    0.176471\n",
      " 1.0    0.117647\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make 5-fold CV splits files based on occlus_elast_cat, non-extreme data\n",
    "\n",
    "createStratifiedShuffleSplits(df = unilever_1_df, extreme_data = False, strat_feature = \"occlus_elast_cat\", dest_directory = './5_fold_stratified_splits_high_30_occlusives_elastomers_false')\n",
    "\n",
    "# cannot make the no-occlusive train/test splits using the stratified shuffle splits approach - need to make those\n",
    "# files manually by manually eliminating those records with occlusive_cat = 4.  The random split will not work \n",
    "# the way we want given that the records with occlusive_cat = 4 have been eliminated from the dataset.\n",
    "# do not use this code!...\n",
    "# createStratifiedShuffleSplits(df = unilever_2_df, fieldName = \"occlusive_cat\", directoryName = './5_fold_stratified_splits_no_high_occlusives')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occlus_elast_cat Distribution: Complete Data Set\n",
      "Value \t Percentage\n",
      " 4.0    0.322581\n",
      "-0.0    0.282258\n",
      " 3.0    0.209677\n",
      " 2.0    0.120968\n",
      " 1.0    0.064516\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 124\n",
      "\n",
      "occlus_elast_cat Distribution: training set 1\n",
      "Value \t Percentage\n",
      " 4.0    0.323232\n",
      "-0.0    0.282828\n",
      " 3.0    0.212121\n",
      " 2.0    0.121212\n",
      " 1.0    0.060606\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 99\n",
      "\n",
      "occlus_elast_cat Distribution: test set 1\n",
      "Value \t Percentage\n",
      " 4.0    0.32\n",
      "-0.0    0.28\n",
      " 3.0    0.20\n",
      " 2.0    0.12\n",
      " 1.0    0.08\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 25\n",
      "\n",
      "occlus_elast_cat Distribution: training set 1 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "4.0    1.0\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 32\n",
      "\n",
      "occlus_elast_cat Distribution: test set 1 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "4.0    1.0\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 8\n",
      "\n",
      "occlus_elast_cat Distribution: training set 2\n",
      "Value \t Percentage\n",
      " 4.0    0.323232\n",
      "-0.0    0.282828\n",
      " 3.0    0.212121\n",
      " 2.0    0.121212\n",
      " 1.0    0.060606\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 99\n",
      "\n",
      "occlus_elast_cat Distribution: test set 2\n",
      "Value \t Percentage\n",
      " 4.0    0.32\n",
      "-0.0    0.28\n",
      " 3.0    0.20\n",
      " 2.0    0.12\n",
      " 1.0    0.08\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 25\n",
      "\n",
      "occlus_elast_cat Distribution: training set 2 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "4.0    1.0\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 32\n",
      "\n",
      "occlus_elast_cat Distribution: test set 2 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "4.0    1.0\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 8\n",
      "\n",
      "occlus_elast_cat Distribution: training set 3\n",
      "Value \t Percentage\n",
      " 4.0    0.323232\n",
      "-0.0    0.282828\n",
      " 3.0    0.212121\n",
      " 2.0    0.121212\n",
      " 1.0    0.060606\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 99\n",
      "\n",
      "occlus_elast_cat Distribution: test set 3\n",
      "Value \t Percentage\n",
      " 4.0    0.32\n",
      "-0.0    0.28\n",
      " 3.0    0.20\n",
      " 2.0    0.12\n",
      " 1.0    0.08\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 25\n",
      "\n",
      "occlus_elast_cat Distribution: training set 3 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "4.0    1.0\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 32\n",
      "\n",
      "occlus_elast_cat Distribution: test set 3 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "4.0    1.0\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 8\n",
      "\n",
      "occlus_elast_cat Distribution: training set 4\n",
      "Value \t Percentage\n",
      " 4.0    0.323232\n",
      "-0.0    0.282828\n",
      " 3.0    0.212121\n",
      " 2.0    0.121212\n",
      " 1.0    0.060606\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 99\n",
      "\n",
      "occlus_elast_cat Distribution: test set 4\n",
      "Value \t Percentage\n",
      " 4.0    0.32\n",
      "-0.0    0.28\n",
      " 3.0    0.20\n",
      " 2.0    0.12\n",
      " 1.0    0.08\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 25\n",
      "\n",
      "occlus_elast_cat Distribution: training set 4 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "4.0    1.0\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 32\n",
      "\n",
      "occlus_elast_cat Distribution: test set 4 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "4.0    1.0\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 8\n",
      "\n",
      "occlus_elast_cat Distribution: training set 5\n",
      "Value \t Percentage\n",
      " 4.0    0.323232\n",
      "-0.0    0.282828\n",
      " 3.0    0.212121\n",
      " 2.0    0.121212\n",
      " 1.0    0.060606\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 99\n",
      "\n",
      "occlus_elast_cat Distribution: test set 5\n",
      "Value \t Percentage\n",
      " 4.0    0.32\n",
      "-0.0    0.28\n",
      " 3.0    0.20\n",
      " 2.0    0.12\n",
      " 1.0    0.08\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 25\n",
      "\n",
      "occlus_elast_cat Distribution: training set 5 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "4.0    1.0\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 32\n",
      "\n",
      "occlus_elast_cat Distribution: test set 5 after high occlus/elast data points removed\n",
      "Value \t Percentage\n",
      "4.0    1.0\n",
      "Name: occlus_elast_cat, dtype: float64\n",
      "Total count: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make 5-fold CV splits files based on occlus_elast_cat, extreme data\n",
    "\n",
    "createStratifiedShuffleSplits(df = unilever_1_df, extreme_data = True, strat_feature = \"occlus_elast_cat\", dest_directory = './5_fold_stratified_splits_high_30_occlusives_elastomers_true')\n",
    "\n",
    "# cannot make the no-occlusive train/test splits using the stratified shuffle splits approach - need to make those\n",
    "# files manually by manually eliminating those records with occlusive_cat = 4.  The random split will not work \n",
    "# the way we want given that the records with occlusive_cat = 4 have been eliminated from the dataset.\n",
    "# do not use this code!...\n",
    "# createStratifiedShuffleSplits(df = unilever_2_df, fieldName = \"occlusive_cat\", directoryName = './5_fold_stratified_splits_no_high_occlusives')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
